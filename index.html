<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>My Project</title>
<link rel="stylesheet" href="style.css">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
<style>
.project-title {
    font-size: 2.0rem;   /* 제목 크기 */
    line-height: 1.2;    /* 줄 간격 */
}
</style>
</head>
<body>

<!-- Hero Section -->
<section class="text-center py-5">
    <h1 class="display-4 fw-bold project-title">
        SHIFT-RL: Sensor-driven Hierarchical Information Fusion Transformer<br>
        for BEV-based Maneuvering in Dense Multi-lane Environments
    </h1>

    <!-- Authors -->
    <p class="lead mt-3">
        Sungjun Heo<sup>1</sup>, 
        Jeong hwan Jeon<sup>1,2,*</sup>
    </p>
    
    <!-- Affiliations -->
    <p class="mb-4">
        <sup>1</sup>Graduate School of Artificial Intelligence, UNIST<br>
        <sup>2</sup>Department of Electrical Engineering, UNIST<br>
        <sup>*</sup> Corresponding author
    </p>

    <div class="mt-3">
        <a href="paper/paper.pdf" class="btn btn-primary">Paper</a>
        <a href="https://github.com/myrepo" class="btn btn-secondary">Code</a>
        <a href="#video" class="btn btn-success">Video</a>
    </div>
</section>

<!-- Video -->
<section id="video" class="container text-center my-5">
    <h2>Video</h2>
    <div class="ratio ratio-16x9">
        <iframe src="https://www.youtube.com/embed/VIDEO_ID" allowfullscreen></iframe>
    </div>
</section>

<!-- Abstract -->
<section id="abstract" class="container my-5 text-center">
    <h2>Abstract</h2>
    <img src="assets/img/overview.png" class="img-fluid rounded" style="width: 50%;">
    <p>Imitation learning is widely used in end‑to‑end (E2E) autonomous driving, but it is reported to be challenging when tasks require long‑horizon planning or face substantial out-of-distribution (OOD) shifts. Reinforcement learning (RL) based planning is a promising alternative, yet monolithic policies are brittle under sparse rewards and large state spaces. We introduce SHIFT‑RL (Sensor‑driven Hierarchical Information Fusion Transformer for RL), a hierarchical framework that operates on LiDAR‑based bird’s‑eye‑view (BEV) states, fuses spatiotemporal cues with an information‑fusion Transformer, and couples hierarchical policies with curriculum learning. A high‑level policy selects tactical maneuvers; a low‑level policy, conditioned on that choice, outputs vehicle speed, decomposing complex decisions into stable subproblems. We train and evaluate SHIFT‑RL in dense multi‑lane settings that require long‑horizon planning and exhibit significant OOD shifts. Ablations of the hierarchy and curriculum, and comprehensive comparisons against monolithic RL, rule‑based methods, and an imitation learning baseline show that SHIFT‑RL achieves the highest success rate and the lowest collision rate across all evaluated environments. These results indicate that combining an information‑fusion Transformer with hierarchical RL and curriculum learning substantially improves stability and generalization for challenging BEV‑based maneuvering.</p>
</section>

<!-- Pipeline -->
<section class="container my-5 text-center">
    <h2>Pipeline</h2>
    <img src="assets/img/pipeline.png" class="img-fluid rounded" style="width: 75%;">
</section>

</body>
</html>
